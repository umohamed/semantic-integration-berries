---
title: "Uma-formative-assignment-3"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---
#install packages 
```{r}
library("tidyverse")
library("emmeans")
library("performance")
library("see")
library("patchwork")
library(dplyr) 
library(tidyr)
data = read.csv("formative_assignment_3_data.csv")

```

#subject-level means 
```{r}
subject_accuracy = data %>%  
  group_by(subject, prime_condition)   %>%  
  summarize(mean_accuracy = mean(accuracy))
```

#format of subject accuracy is long because there is multiple data points for each subject meaning that there are multiple rows for one subject. 

#long to wide conversion 
```{r}
 subject_accuracy_wide <- subject_accuracy %>%
   pivot_wider(names_from = prime_condition, values_from = mean_accuracy)
```

#Boxplot + Interpretation
```{r}
 plot_data <- subject_accuracy_wide %>%
  pivot_longer(cols = c(semantic, unrelated, both, phonological), names_to = "condition", values_to = "accuracy")
print(plot_data)


ggplot(data = plot_data) + 
  geom_boxplot(mapping = aes(x = subject, y = accuracy, fill = condition)) 

#This boxplot tells us that accuracy improves with phonological prime words than the other prime conditions. The both condition seems to have better accuracy than the semantic and unrelated conditions. 
```

#Linear Model 
```{r}
library(lmerTest)
subject_level_model = lmer(data = plot_data, accuracy ~ condition + (1|subject)) 
summary(subject_level_model)
subject_level_model_2 = aov(data = plot_data, accuracy ~ condition + (1|subject)) 
summary(subject_level_model_2)

```

#Linear Model Interpretation
```{r}
#Yes, there is a main effect of prime condition on accuracy. After creating a mixed liner model of the data, the analysis reveled a significant main effect of condition, F (3, 144) = 4.18, p = 0.00716.  Further, it is the phonological condition that is significantly influenced accuracy, p = 0.00116.The other conditions, both, semantic and unrelated did not reach statistical significance. 

```

#Linear Model Equation 
```{r}
#a) The condition coefficients are as follows: phonological: 0.090811, semantic: -0.040000, unrelated: 0.007568 and as the reference category both is 0. 
#b) The reference category is the both condition. 
#c) Accuracy = 0.262702703 + phonological(0.090810811) + semantic(-0.040000000) + unrelated( -0.007567568)
#d) Accuracy from both to phonological increases to 0.090810811 from 0. While accuracy from both to semantic decreases to -0.04 from 0.

```
#Post-hoc tests 
```{r}
library(emmeans)
emmeans :: emmeans (subject_level_model, 
                    pairwise ~ condition,
                    adjust = "tukey")

#The phonological condition is significantly different from all the other conditions with each comparison having a significant p value. 
```
#Assumption check 
```{r}
library(performance)
check_model(subject_level_model)

#The two assumptions that the data is not meeting perfectly are linearity and homogeneity of variance. The reference line for linearity is not completely flat and horizontal but curves up at the end. While, the reference line of homogeneity of variance is not completely flat and horizontal either and curves up at the end too. The other assumptions seem to fit the data fine.
```


#Overall pattern interpretation: No, I think the data fits the test of assumpations relatively decent and that there is minimal effect on the validty of linear model. I conclude that people are mostly like to retrive words from memory when they are helped with a phonological cue. This is compared to when using semantic cues or cues are both phonological and semantic, as well as unrelated cues which can be expected. 

#State Prime Data
```{r}
state_prime_acc = data %>% 
  group_by(subject, state, prime_condition ) %>%
  summarize(mean_accuracy = mean(accuracy))
```

#State Prime Model 
```{r}
state_prime_acc_model = lmer(data = state_prime_acc, mean_accuracy ~ prime_condition*state +  (1|subject)) 
summary(state_prime_acc_model)
state_prime_acc_model_2 = aov(data = state_prime_acc, mean_accuracy ~ prime_condition*state +  (1|subject)) 
summary(state_prime_acc_model_2)

#I can conclude that the states know and tipoftongue are statistically significant Also, there are statistically significant results when a phonological prime is used when the state is other. 

#There is a main effect of prime condition on accuracy, F(3, 544) = 4.858, p = 0.00241.There is a main effect of state on accuracy, F (3, 544) = 214.546, p = < 0.001.

#There is a interaction of prime condition and state on accuracy, F(9, 544) = 2.046, p = 0.03267.

```

#Post Hoc Tests 
```{r}
emmeans :: emmeans (state_prime_acc_model, 
                    pairwise ~ prime_condition | state, 
                    adjust = "tukey")

#For the I dont know state none of the conditions were helpful in influencing accuracy. For the know state, the phonological and semantic conditions were helpful in influencing accuracy. while others were not . For the other state, the both, phonological and semantic conditions were helpful in influencing accuracy. while unrelated was  not. For the tipoftongue state, none of the conditions were helpful in influencing accuracy.

```

