---
title: "first_notebook"
output: html_document
date: "2023-10-17"
---
# install packages

```{r}
library(tidyverse)
library(ggplot2)
```


# tidyverse verbs

```{r}
objectdata = read.csv("objects.csv") %>%
  mutate(rt = as.numeric(rt), weight = as.factor(weight), shape = as.factor(shape)) 
          
nrow(objectdata)
ncol(objectdata)
condition_data = objectdata %>%
  filter(typeoftrial == "picture" & weight %in% c("Heavy", "Light") & shape %in% c("Normal", "Smashed") & correct == TRUE)  %>%
  select(subject, rt, weight, shape, correct)
```

```{r}
object_agg = condition_data  %>%
  group_by(subject,weight,shape)   %>%
  summarise(mean_rt = mean(rt), sd_rt = sd(rt))
  
```

```{r}
ggplot(data = object_agg) + 
  geom_col(mapping = aes(x=shape, y = mean_rt, fill = weight),position = "dodge") +
  theme_bw() +
  labs(title = "plot of RTs", y = "Response Times (MS)") +
  scale_fill_grey()


```

#load revised class data 
```{r}
revised_data = read_csv("final_class_data.csv") %>%
  mutate(rt = as.numeric(rt), 
         relatedness = as.factor(relatedness),
         type = as.factor(type))
```

#looking at revised_data 
```{r}
nrow(revised_data)
levels(revised_data$relatedness) #only works bc is a factor
revised_data %>% group_by(ID) %>% count()
revised_data %>% filter(typeoftrial == "target") %>% group_by(ID) %>% count()
revised_data  %>% filter(typeoftrial == "target") %>% pull(rt)
revised_data  %>% pull(ID)   %>%  unique() 

```

#attention
```{r}
attention_trials = revised_data %>% filter(typeoftrial == "attention") %>% 
  select(ID, revised_response, novel1, novel2, novel3, revised_correct)

# summarize particpant accuracy 
subject_attention_accuracy = attention_trials %>% 
  group_by(ID)  %>% 
  summarize(mean_accuracy = mean(revised_correct), 
            sd_accuracy = sd(revised_correct))


low_acc_IDs = subject_attention_accuracy  %>% 
  filter(mean_accuracy < 0.75)  %>% 
  pull(ID)

```

#priming trials 
```{r}
priming_data = revised_data    %>%  
  filter(typeoftrial == "target")    %>%  
  select(ID, rt, relatedness, prime, response, type, correct, block_number, target, correct_key) %>%  filter(!is.na(rt), rt > 200, rt < 1500, correct == "TRUE", block_number == 1)  %>%  
  filter(relatedness %in% c("related", "unrelated") & type %in% c("direct", "shared"))  %>%  
  filter(!ID %in% low_acc_IDs) 

#
```

#plot 
```{r}
priming_data %>%  
  group_by(type, relatedness) %>%  
  summarise(mean_rt = mean(rt)) %>%  
  ggplot  + 
  geom_col(mapping = aes(x = type, y = mean_rt, group = relatedness, fill = relatedness), position = "dodge") + 
  theme_bw()+
  scale_fill_grey()
             
```

#association 
```{r}
scoring = read_csv("association_scoring.csv") %>%  
  arrange(cue, response) 
association_trials = revised_data %>%  
  filter(typeoftrial == "association")%>% 
  select(ID,revised_response, cue) %>%  
  rename(response = "revised_response")  %>%  
  mutate(response = tolower(response))  %>% 
  left_join(scoring)

congruence_trials = association_trials %>%  
  filter(!is.na(congruence))  %>%
  filter(congruence %in% c("congruent" , "incongruent"))  %>%  
  filter(type_of_association %in% c("direct", "shared"))

#counts by congruence 
congruence_counts = congruence_trials  %>%  
  group_by(ID, cue_type, congruence, type_of_association) %>% 
  count() %>% 
  group_by(ID, cue_type) %>% 
  mutate(proportion = n / sum(n))
  
congruence_counts   %>%  
  filter(congruence == "congruent")  %>%  
  ungroup()  %>%  
  summarise(mean_prop = mean(proportion))

wide_counts = congruence_counts   %>%  
  select(ID, cue_type, congruence, type_of_association,proportion) %>% 
  pivot_wider(names_from = congruence, values_from = proportion) %>% 
  mutate(incongruent = ifelse(is.na(incongruent), 0, incongruent), 
         congruent = ifelse(is.na(congruent), 0, congruent))%>% 
  mutate(prop = congruent - incongruent)

mean(wide_counts$prop) #ts is wht we wete doing all this for and need to recreate for our project 
#counts by type of associaton 

association_type_occurrence = wide_counts %>%  
   select(ID, cue_type, type_of_association,prop)  %>% 
  pivot_wider(names_from = type_of_association, values_from = prop) %>% 
  mutate(shared = ifelse(is.na(shared), 0, shared), 
         direct = ifelse(is.na(direct), 0, direct))

mean(association_type_occurrence$direct)
mean(association_type_occurrence$shared)
  

#need 3 things: overall % of congurent responses, direct and shared 
  


```

#linear models 
```{r}
data(women)
ggplot(data = women) + 
  geom_point(mapping = aes(x = weight, y = height ))

women  %>% 
  ggplot(aes(x = weight, y = height)) +
  geom_point() +
  geom_smooth(method = "lm") +
  theme_classic() 

women_model = lm(data = women, height ~ weight) 
summary(women_model)
# equation of line is height = 0.287(weight) + 25.72
sd(women$height)
sd(women$weight)
#women = women   %>% 
 # mutate(z_height = scale(height), z_weight = scale(weight))
sd(women$height)
sd(women$weight)
#women_model_2 = lm(data = women, z_height, z_weight)
#summary(women_model_2)
#women  %>% 
  #summarise(r = cor(z_height, z_weight))

```
#iris
```{r}
iris_subset = iris %>%
  filter(Species %in% c("setosa", "virginica"))

iris_subset %>%
  ggplot(aes(x = Species, y = Petal.Length)) +
  geom_col()

iris_subset_lm = lm(data = iris_subset, Petal.Length ~ Species)
summary(iris_subset_lm)

t.test(Petal.Length ~ Species, data = iris_subset)
```

```{r}
full_iris_model = lm(data = iris, Petal.Length ~ Species)
summary(full_iris_model)

full_iris_aov = aov(data = iris, Petal.Length ~ Species)
summary(full_iris_model)
```

```{r}
#install.packages("emmeans")
emmeans::emmeans(full_iris_model, 
                 pairwise ~ Species, adjust="tukey")
```

```{r}
install.packages("performance", dependencies = TRUE)
install.packages("see", dependencies = TRUE)
install.packages("patchwork", dependencies = TRUE)
library(performance)
check_model(full_iris_model)

```

```{r}
install.packages("datarium")
data("jobsatisfaction", package = "datarium")
view(jobsatisfaction)
```


```{r}
ggplot(data = jobsatisfaction) + 
  geom_boxplot(mapping = aes( x = gender, y = score, fill = education_level))
```

```{r}
job_model = lm(data = jobsatisfaction, score ~ gender + education_level + gender:education_level )
summary(job_model)
car::Anova(job_model)
```

```{r}
install.packages("emmeans")
```

```{r}
emmeans :: emmeans(job_model,
                   pairwise ~ gender | education_level,
                   adjust = "tukey")

check_model(job_model)

```

```{r}
rt_lm_model = lm(data = priming_data, rt ~ relatedness + type + relatedness:type)
summary(rt_lm_model)
check_model(rt_lm_model)
library(lmerTest)
rt_model = lmer(data = priming_data, rt ~ relatedness*type + (1|ID))
summary(rt_model)
car::Anova(rt_model)
check_model(rt_model)
```

