---
title: "Semantic Integration Berries"
output: html_document
date: "2023-11-21"
---
# Load Packages
```{r}
library(tidyverse)
library(emmeans)
library(performance)
library(see)
library(patchwork)
library(dplyr)
library(tidyr)
library(lme4)
```


#Import Data 
```{r}
#prolific_data = read.csv("")
#sona_data = read.csv("")
```

# Import data 
```{r}
library(dplyr)
pilot_data = read.csv("sona_data_2.csv") %>%
  mutate(rt = as.numeric(rt),
         relatedness = as.factor(relatedness),
         type = as.factor(type),
         cooccurrence = as.factor(cooccurrence),
         revised_correct = as.numeric(revised_correct))
```

#Inspect Data 
```{r}
nrow(pilot_data)
ncol(pilot_data)
pilot_data %>% #small dataset currently 
  pull(ID) %>% 
  unique() %>%
  length()
pilot_data %>% filter(typeoftrial == "target") %>% group_by(ID) %>% count()
#IV: cooccurrence and relatedness
#DV: rt and revised_correct
cleaned_data = pilot_data %>%
   filter(relatedness != "") %>%
   filter(cooccurrence != "")
levels(cleaned_data$relatedness)
levels(cleaned_data$cooccurrence)
```

#Basic Descriptives 
```{r}
pilot_data %>%
  filter(typeoftrial == "attention")  %>% 
  summarise(mean_accuracy = mean(revised_correct), mean_sd = sd(revised_correct))

target_data = pilot_data %>%
  filter(typeoftrial == "target") 
ggplot(data = target_data) +
  geom_histogram(mapping = aes(x = rt))

target_rt = pilot_data   %>% 
  group_by(ID)  %>% 
  filter(typeoftrial == "target")  %>% 
  summarise(mean_rt = mean(rt))

#revised_correct for target showing NA when trying to get mean accuracy and rt 
subject_accuracy = pilot_data   %>% 
  group_by(ID)  %>% 
  filter(typeoftrial == "attention")  %>% 
  summarise(mean_accuracy = mean(revised_correct))

subject_rt = pilot_data   %>% 
  group_by(ID,typeoftrial )  %>% 
  filter(typeoftrial == "attention" )  %>% 
  summarise(mean_rt = mean(rt))

ggplot(data = cleaned_data, aes(x = cooccurrence, y = rt, fill = relatedness)) +
  geom_col(position = "dodge") +
  labs(title = "Reaction Time by Cooccurrence and Relatedness",
       x = "Cooccurrence",
       y = "Reaction Time",
       fill = "Relatedness")
#In our 7 person study, people had quicker responses when the prime word was a related word that was trained with our target words (apple/horse)like dodish and represents a new co-occurence association. In the pre-existing co-occurence condition, surprisingly related prime words like caramelizing did not show faster reaction times compared to unrelated prime words like narrow. 
# Note that novel relatedness with novel cooccurrence will be removed because that is the practice condition. 
```

#Inferential Statistics 
```{r}
#Reseach Q: We will be investigating how closely related a novel co-occurring word is to the target word compared to pre-existing co-occurring related and unrelated words. We are asking if the novel co-occurring words are as integrated into our semantic network as pre-existing related words. 

rt_model = lmer(data = priming_data,
                rt ~ relatedness*cooccurrence + (1|ID))
summary(rt_model)
car :: Anova(rt_model)
```

#Following is our analysis 

# Attention

```{r}
attention_trials = pilot_data %>% filter(typeoftrial == "attention") %>%
  select(ID, revised_response, novel1, novel2, novel3, revised_correct)

## Mean
attention_trials %>%
  summarize(mean_accuracy = mean(revised_correct),
            sd_accuracy = sd(revised_correct))

## Summarize Participant Activity 
subject_attention_accuracy = attention_trials %>%
  group_by(ID) %>%
  summarize(mean_accuracy = mean(revised_correct))

## Find IDs that have less than 75% accuracy
low_acc_IDs = subject_attention_accuracy %>%
  filter(mean_accuracy < 0.75) %>%
  pull(ID)
```

# Priming
```{r}
priming_data = pilot_data %>% filter(typeoftrial == "target") %>%
  select(ID, rt, relatedness, prime, response, type, cooccurrence, correct, block_number, target, correct_key) %>%
  filter(!is.na(rt), rt > 250, rt < 1500, correct == "TRUE", block_number == 1) %>%
  filter(relatedness %in% c("related", "unrelated") & cooccurrence %in% c("novel", "preexisting")) %>%
  filter(!ID %in% low_acc_IDs)

## CHANGE TYPE TO COOCCURENCE (NOVEL AND PREEXISTING)
```

# Plot 
```{r}
priming_data %>% 
  group_by(cooccurrence, relatedness) %>%
  summarize(mean_rt = mean(rt)) %>%
  ggplot() +
  geom_col(mapping = aes(x= cooccurrence, y = mean_rt,
                         group = relatedness, fill = relatedness),
           position = "dodge")+
  theme_bw()+
  scale_fill_grey()

```

# Association
```{r}
scoring = read_csv("association_scoring.csv")%>%
  arrange(cue, response)

association_trials = pilot_data %>%
  filter(typeoftrial == "association") %>%
  select(ID, revised_response, cue) %>%
  rename(response = "revised_response") %>%
  mutate(response= tolower(response)) %>%
  left_join(scoring)

congruence_trials = association_trials %>%
  filter(!is.na(congruence)) %>%
  filter(congruence %in% c("congruent", "incongruent")) %>%
  filter(type_of_association %in% c("direct", "shared"))

## NEED TO WORK AROUND THE MIPP AND GECK RESPONSES SINCE THEY AREN'T ASSOCIATED WITH A TRIAD

congruence_trials = association_trials %>%
  filter(!is.na(congruence)) %>%
  filter(congruence %in% c("congruent", "incongruent")) %>%
  filter(type_of_association %in% c("direct", "shared"))

congruence_counts = congruence_trials %>%
  group_by(ID, cue_type, congruence, type_of_association) %>%
  count() %>%
  group_by(ID, cue_type) %>%
  mutate(proportion = n / sum(n))

congruence_counts %>%
  filter(congruence == "congruent") %>%
  ungroup()%>%
  summarise(mean_prop = mean(proportion)) 

wide_counts = congruence_counts %>%
  select(ID, cue_type, congruence, type_of_association, proportion) %>%
  pivot_wider(names_from = congruence, values_from = proportion) %>%
  mutate(incongruent = ifelse(is.na(incongruent), 0, incongruent),
         congruent = ifelse(is.na(congruent), 0, congruent)) %>%
  mutate(prop = congruent - incongruent)

mean(wide_counts$prop)

## counts by type of association 

association_type_occurrence = wide_counts %>%
  select(ID, cue_type, type_of_association, prop) %>%
  pivot_wider(names_from = type_of_association, values_from = prop) %>%
  mutate(shared = ifelse(is.na(shared), 0, shared),
         direct = ifelse(is.na(direct), 0, direct))

mean(association_type_occurrence$direct)
mean(association_type_occurrence$shared)
```
